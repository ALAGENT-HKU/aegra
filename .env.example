# Database
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5442/aegra
# User database for quantitative_strategy_agent (auth, sessions)
USER_DATABASE_URL=postgresql+asyncpg://alagent:alagent@localhost:5435/alagent


# Logs
# File Logging (enabled for Docker persistence)
LOG_TO_FILE=true  # Set to 'true' to enable file logging
LOG_FILE_PATH=logs/aegra.log  # Path to log file (mounted to host via docker-compose)
LOG_FILE_MAX_BYTES=10485760  # Max file size before rotation (default: 10MB)
LOG_FILE_BACKUP_COUNT=5  # Number of backup files to keep

DB_USER=user
DB_PASSWORD=password
DB_HOST=localhost
DB_PORT=5442
DB_NAME=aegra

SA_POOL_SIZE=2
SA_MAX_OVERFLOW=0
LG_MIN_POOL_SIZE=1
LG_MAX_POOL_SIZE=6

# Authentication (extensible)
AUTH_TYPE=custom  # noop, custom

# Server
HOST=0.0.0.0
PORT=2024
DEBUG=true

# Logging
LOG_LEVEL=INFO
ENV_MODE=LOCAL # DEVELOPMENT, PRODUCTION, LOCAL (PRODUCTION outputs JSON logs)
LOG_VERBOSITY=standard # standard, verbose (verbose outputs request-id for each request)

# LLM Providers
OPENAI_API_KEY=sk-your-key-here
# ANTHROPIC_API_KEY=...
# TOGETHER_API_KEY=...

# Langfuse Integration - 连接本地 Langfuse (运行在 7312)
LANGFUSE_LOGGING=true
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key-here
LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key-here
LANGFUSE_HOST=http://localhost:7312
LANGFUSE_TIMEOUT=30
OTEL_EXPORTER_OTLP_TIMEOUT=30000


#---- PASTE HERE FROM quantitative_strategy_agent/.env ----

# Redis (已有)
REDIS_URL=redis://localhost:6380/0

# 邮件服务 - Resend
RESEND_API_KEY=re_your_resend_api_key_here
RESEND_FROM_EMAIL=noreply@alagentai.com

# ============================================================================
# Authentication Configuration
# ============================================================================
JWT_SECRET=your-jwt-secret-here
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=720  # 30 days

# ============================================================================
# Local Qwen Model Configuration (vLLM deployment)
# ============================================================================
LOCAL_QWEN_ENDPOINT=http://202.45.128.234:5788/v1/
LOCAL_QWEN_MODEL_NAME=/nfs/whlu/models/Qwen3-Coder-30B-A3B-Instruct
LOCAL_QWEN_API_KEY=none

# Model Selection: "qwen" (local), "claude" (Anthropic), or "gemini" (Google)
RESEARCH_MODEL=qwen
#==================================== NEED TO SET THESE ====================================
PERSIST_DIR="../data/database"


# ============================================================================
# Model APIs for SubGraph and Each Stage Agent
# ============================================================================

MODEL_MODE=dev

# Anthropic API Key (for Claude Sonnet 4)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI API Key (for GPT-4o-mini summarization)
OPENAI_API_KEY=your_openai_api_key_here

# Google API Key (for Gemini)
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_PROJECT_ID=graphic-armor-148222
GOOGLE_CLOUD_LOCATION=global
GOOGLE_GENAI_USE_VERTEXAI=TRUE

# ZhipuAI GLM-4 (智谱AI)
# Get API key from: https://open.bigmodel.cn/usercenter/apikeys
ZHIPUAI_API_KEY=your_zhipuai_api_key_here
GLM4_MODEL=glm-4.7  # Options: glm-4.7, 

# Other Services
# LLAMA_CLOUD_API_KEY=llx-VJ54LXwJ2UvZSwGpH5hikKUcZVqKgDTiVDoCLe6ULmOtkD1y
OPENBB_PAT=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdXRoX3Rva2VuIjoiNkhuTkFOSWNkNFE0VjhzcGFyb2hkeG1XcHVOMldPS0xQMVY4TzVMUCIsImV4cCI6MTc5Nzg0NjQwMH0.9Ow9kCEdpQadCpPtRDcdeoI4m2QJHiz_dghNgEkuhag


DATA_AGENT_MAX_RETRIES=0

# ============================================================================
# Model Selection per Agent (Options: gemini, qwen_local, claude, glm4)
# ============================================================================
# Main Agent Model (orchestration and delegation)
MAIN_AGENT_MODEL=glm4

# Data Agent Model (data fetching and preparation)
DATA_AGENT_MODEL=qwen_local

# Signal Agent Model (for strategy logic generation)
SIGNAL_AGENT_MODEL=gemini

# Integration Agent Model (for code assembly)
INTEGRATION_AGENT_MODEL=gemini


# ============================================================================
# Tool APIs
# ============================================================================
# Tavily API Key (for web search)
TAVILY_API_KEY=your_tavily_api_key_here

# LangSmith API Key (required for LangGraph local server)
# Get your key at: https://smith.langchain.com/settings
LANGSMITH_API_KEY=your_langsmith_api_key_here

# LangSmith Tracing Configuration
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_PROJECT=quantitative-strategy-agent


# # Model Configuration
# MODEL_TYPE=qwen
# MODEL_NAME=${LOCAL_QWEN_MODEL_NAME}
# MODEL_ENDPOINT=http://202.45.128.234:5788/v1/
# MODEL_API_KEY=none
# MODEL_TEMPERATURE=0.0
# MODEL_MAX_TOKENS=8000

# Summarization Model (for context compression)
SUMMARY_MODEL=${LOCAL_QWEN_MODEL_NAME}
SUMMARY_TRIGGER_TOKENS=80000
SUMMARY_KEEP_MESSAGES=15

# Backend Configuration
WORKSPACE_DIR=/home/whlu/ALAGENT/deepagents-quickstarts/data/workspace
MEMORIES_DIR=/home/whlu/ALAGENT/deepagents-quickstarts/data/memories
BASE_DATA_DIR=/home/whlu/ALAGENT/deepagents-quickstarts/data

# Docker Configuration
DOCKER_IMAGE=backtestlite-slave:latest
DOCKER_TIMEOUT=300
DOCKER_MEMORY_LIMIT=4g

# Agent Limits
MAX_CONCURRENT_SUBAGENTS=3
MAX_RETRIES=3
MAX_EXECUTION_TIME=600

# Feature Flags
ENABLE_SUMMARIZATION=true
ENABLE_HUMAN_IN_LOOP=true


HOST_BASE_DATA_DIR=/home/whlu/ALAGENT/deepagents-quickstarts/data
HOST_WORKSPACE_DIR=/home/whlu/ALAGENT/deepagents-quickstarts/data/workspace
GCP_ADC_PATH=/home/whlu/.config/gcloud/application_default_credentials.json
